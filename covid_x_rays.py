# -*- coding: utf-8 -*-
"""covid x-rays.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ud6Wog_wGm8Q1-qbw_Heuk9e2OxtrwU4
"""

import re
import os
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import os
if not os.path.isdir('/content/drive'):
    from google.colab import drive
    drive.mount('/content/drive')
else:
    print("Google drive is mounted !")

#下載資料集
base_dir = '/content/drive/MyDrive/資料視覺化'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'val')
test_dir = os.path.join(base_dir, 'test')

train_normal_dir = os.path.join(train_dir, 'normal')           # 取得訓練用正常肺部圖片的路徑
train_covid_dir = os.path.join(train_dir, 'covid-19')           # 取得訓練用covid-19圖片的路徑
validation_normal_dir = os.path.join(validation_dir, 'normal') # 取得驗證用正常肺部圖片的路徑
validation_covid_dir = os.path.join(validation_dir, 'covid-19') # 取得驗證用covid-19圖片的路徑
test_normal_dir = os.path.join(test_dir, 'normal') # 取得測試用正常肺部圖片的路徑
test_covid_dir = os.path.join(test_dir, 'covid-19') # 取得測試用covid-19圖片的路徑

train_normal_fnames = os.listdir(train_normal_dir)              # 取得訓練用所有正常肺部圖片
train_covid_fnames = os.listdir(train_covid_dir)              # 取得訓練用所有covid-19圖片
validation_normal_fnames = os.listdir(validation_normal_dir)    # 取得驗證用所有正常肺部圖片
validation_covid_fnames = os.listdir(validation_covid_dir)    # 取得驗用所有covid-19圖片
test_normal_fnames = os.listdir(test_normal_dir)    # 取得測試用所有正常肺部圖片
test_covid_fnames = os.listdir(test_covid_dir)    # 取得測試用所有covid-19圖片

# Commented out IPython magic to ensure Python compatibility.
#檢視資料集
# %matplotlib inline
 
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
 
# 設定顯示列數(row)及行數(col)皆為4
nrows = 4
ncols = 4
 
# 圖像索引編號
pic_index = 0
 
# 設定繪圖參數使其可容納4x4張圖像
fig = plt.gcf()
fig.set_size_inches(ncols * 4, nrows * 4)
 
# 設定下一次顯示圖像內容，正常及covid-19各8張
pic_index += 8
next_normal_pix = [os.path.join(train_normal_dir, fname) 
                for fname in train_normal_fnames[pic_index-8:pic_index]]
next_covid_pix = [os.path.join(train_covid_dir, fname) 
                for fname in train_covid_fnames[pic_index-8:pic_index]]
 
# 將取得圖像內容繪製至容器中
for i, img_path in enumerate(next_normal_pix+next_covid_pix):
  sp = plt.subplot(nrows, ncols, i + 1)
  sp.axis('Off') # 取消軸標示及格線
 
  img = mpimg.imread(img_path)
  plt.imshow(img)
 
# 顯示結果
plt.show()

#建立卷積神經網路CNN
#共有三層卷積層(包含ReLu及Max Pooling)
import tensorflow as tf

from keras.models import Model
from keras import layers
from keras import backend as K



# 輸入層為150x150x3的資料，其中的3表示RGB三個通道。
img_input = layers.Input(shape=(150, 150, 3))

# 經過第一卷積層(Conv2D)的共產生16組3x3x3濾波器並搭配ReLu激活(Activation)函數
#接著以2x2窗口進行最大池化(Max Pooling)動作，取出四個值中最大值
x = layers.Conv2D(16, 3, activation='relu')(img_input)
x = layers.MaxPooling2D(2)(x)

# 再來是第二卷積層(Conv2D)，這項動作類似步驟2，產生32組3x3x16濾波器，同樣搭配ReLu激活(Activation)函數
x = layers.Conv2D(32, 3, activation='relu')(x)
x = layers.MaxPooling2D(2)(x)

# 再來進行第三卷積層(Conv2D)的共產生64組3x3x32濾波器並搭配ReLu激活(Activation)函數
x = layers.Conv2D(64, 3, activation='relu')(x)
x = layers.MaxPooling2D(2)(x)

# 將所有節點展開(Flatten)變成一維節點準備進行下一階段的全連結網路
x = layers.Flatten()(x)

# 再來以512個節點和上一層進行全連結(Dense)，並搭配ReLu激活函數，再加上一個偏置值(Bias)一起訓練
x = layers.Dense(512, activation='relu')(x)

# 最後只留一個輸出節點和上一層進行全連結(Dense)並搭配Sigmoid激活函數來產生最後輸出結果，加上一個偏置值(Bias)
output = layers.Dense(1, activation='sigmoid')(x)

# Create model:
# input = input feature map
# output = input feature map + stacked convolution/maxpooling layers + fully 
# connected layer + sigmoid output layer
model = Model(img_input, output)

# 展示模型結構及各層所需訓練參數
model.summary()

#模型配置及訓練優化設定
#用binary_crossentropy損失來訓練模型
from keras.optimizers import RMSprop

model.compile(loss='binary_crossentropy',
              optimizer=RMSprop(learning_rate=0.001),
              metrics=['acc'])

from keras.preprocessing.image import ImageDataGenerator

# 像素原本是介於0-255，正規化後成0-1
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)


train_generator = train_datagen.flow_from_directory(
        train_dir,  
        target_size=(150, 150),  #所有照片調整成 150x150
        batch_size=23, #一次讀取23張照片
      
        class_mode='binary')


validation_generator = test_datagen.flow_from_directory(
        validation_dir,
        target_size=(150, 150),
        batch_size=23,
        class_mode='binary') #分類方式為二進制(非0即1)，再各別生成訓練及驗證用數據產生器

history = model.fit_generator(
      train_generator,
      steps_per_epoch=32,  # 736 images = batch_size * steps
      epochs=10,
      validation_data=validation_generator,
      validation_steps=4,  # 92 images = batch_size * steps
      verbose=1)
#正確率(Accuracy)是否有逐漸提高、逐漸收歛

#藍線代表訓練集結果，而橘線代表驗證集結果
acc = history.history['acc']
val_acc = history.history['val_acc']


loss = history.history['loss']
val_loss = history.history['val_loss']


epochs = range(len(acc))


plt.plot(epochs, acc)
plt.plot(epochs, val_acc)
plt.title('Training and validation accuracy')

plt.figure()


plt.plot(epochs, loss)
plt.plot(epochs, val_loss)
plt.title('Training and validation loss')

import numpy as np
import random
from keras.preprocessing.image import img_to_array, load_img


normal_img_files = [os.path.join(test_normal_dir, f) for f in test_normal_fnames]
covid_img_files = [os.path.join(test_covid_dir, f) for f in test_covid_fnames]
img_path = random.choice(normal_img_files + covid_img_files)


img = load_img(img_path, target_size=(150, 150)) 
plt.title(img_path)
plt.grid(False)
plt.imshow(img)

# 將圖像轉成模型可分析格式(150x150x3)
x = img_to_array(img)  # Numpy array with shape (150, 150, 3)
x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)
x /= 255 # Rescale by 1/255

import time
start = time.time() # 啟動計時器

result = model.predict(x) # 對輸入圖像進行推論(預測)

finish = time.time() # 結束計時器

print ("Result = %f" %result) # 印出結果可能機率值(0.0 ~ 1.0)
print("Test time :%f second." %(finish-start)) # 印出推論時間

#設定分類門檻值並印出推論結果
covid_threshold = 0.6
mid_threshold = 0.4
normal_threshold = 0.2

if result > covid_threshold:    # result 介於0.6 至 1.0 為covid
    print("This is covid-19.") 
elif result >= mid_threshold: # result 介於0.4 至 0.6 可能為covid
    print("Maybe is covid-19")
elif result < normal_threshold:  # result 介於0.2 至 0.4 可能為normal
    print("This is normal")
else:                         # result 介於0.0 至 0.2 為normal
    print("Maybe is normal.")